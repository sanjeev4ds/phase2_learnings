{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"app1\").getOrCreate()"
      ],
      "metadata": {
        "id": "1o_gqeYErma6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Create an empty DataFrame**\n",
        "#### *You can create an empty DataFrame using spark.createDataFrame with no data.*"
      ],
      "metadata": {
        "id": "sdHqDHEXs8d0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Empty DataFrame with no data\n",
        "empty_df = spark.createDataFrame([],\"id Int, name String\")\n",
        "empty_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_kFcABtr_xt",
        "outputId": "7a2f9ed1-6ad0-429d-d220-4ed0aae354fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "+---+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Convert RDD to DataFrame**\n",
        "#### *To convert an RDD to DataFrame, you need to define the schema*"
      ],
      "metadata": {
        "id": "QDz5ZKn_ssUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.parallelize([(1,\"Alice\"),(2,\"Bob\")])\n",
        "columns = [\"id\", \"name\"]\n",
        "df_from_rdd = rdd.toDF(columns)\n",
        "df_from_rdd.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mmew-BA3sSGF",
        "outputId": "3555a4db-47e9-4f92-87f2-21114beb3534"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  1|Alice|\n",
            "|  2|  Bob|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Convert DataFrame to Pandas**\n",
        "#### *You can convert a PySpark DataFrame to a Pandas DataFrame using toPandas()*\n"
      ],
      "metadata": {
        "id": "n2NxT5FKt2Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_df = df_from_rdd.toPandas()\n",
        "print(pandas_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueuX6w4zsrfc",
        "outputId": "026647b4-e177-4a1c-af96-d329e84ceea0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id   name\n",
            "0   1  Alice\n",
            "1   2    Bob\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. show()**\n",
        "#### *The show() method displays the first n rows of a DataFrame*"
      ],
      "metadata": {
        "id": "yQXY-IX1w-5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_from_rdd.show(5) #display first 5 rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjJYd-OEuMtE",
        "outputId": "2df7b969-d45b-49c7-88b7-07252511b474"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  1|Alice|\n",
            "|  2|  Bob|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. StructType & StructField**\n",
        "#### *These classes are used to define the schema for DataFrames.*"
      ],
      "metadata": {
        "id": "-oi46KOaxXPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
      ],
      "metadata": {
        "id": "uLLXlYgJxVIo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType(), True),\n",
        "    StructField(\"name\",StringType(), True)\n",
        "])\n",
        "\n",
        "data_required = [(1,\"Alice\"), (2,\"Bob\")]\n",
        "df_with_schema = spark.createDataFrame(data_required, schema)\n",
        "df_with_schema.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hupJzrZx2Jl",
        "outputId": "f07f9d38-b763-47fc-cbca-af3e3369e3a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  1|Alice|\n",
            "|  2|  Bob|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Column Class**\n",
        "#### *The column class represents a column in a DataFrame and is used for performing operations.*"
      ],
      "metadata": {
        "id": "uNII8Lhzy8vB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "df_with_column = df_from_rdd.withColumn(\"upper_name\", F.upper(\"name\"))\n",
        "df_with_column.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQgkUsx7y64S",
        "outputId": "9238e8d2-614b-431a-821c-9a69e0740a74"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+\n",
            "| id| name|upper_name|\n",
            "+---+-----+----------+\n",
            "|  1|Alice|     ALICE|\n",
            "|  2|  Bob|       BOB|\n",
            "+---+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. select**\n",
        "#### *The select() method is used to select specific columns.*"
      ],
      "metadata": {
        "id": "2wjLI3Jlzk3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_from_rdd.select(\"id\").show() #selected only id column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbGwDPM2zhtv",
        "outputId": "0cfa9e7f-aa65-4812-dadc-091afcc0c806"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  1|\n",
            "|  2|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. collect**\n",
        "#### *collect() returns all the rows as a list of Row objects.*"
      ],
      "metadata": {
        "id": "5kEP-l-gz674"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = df_from_rdd.collect()\n",
        "print(rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-9npYV2z3K1",
        "outputId": "76f4a1c0-8bbc-4992-916a-145c9855fc91"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(id=1, name='Alice'), Row(id=2, name='Bob')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. **withColumn()**\n",
        "#### *This method is used to add or modify a column*"
      ],
      "metadata": {
        "id": "ceUn06iD1zv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_new_col = df_from_rdd.withColumn(\"id_squared\", F.col(\"id\")**2)\n",
        "df_with_new_col.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQo2oq7J0KLy",
        "outputId": "a54aaab1-603d-4d32-8a9e-196465d8531d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+\n",
            "| id| name|id_squared|\n",
            "+---+-----+----------+\n",
            "|  1|Alice|       1.0|\n",
            "|  2|  Bob|       4.0|\n",
            "+---+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. **withColumnRenamed()**\n",
        "#### *Renames an existing column in the DataFrame*"
      ],
      "metadata": {
        "id": "SRBUpicl2mUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_renamed = df_from_rdd.withColumnRenamed(\"name\", \"full_name\")\n",
        "df_renamed.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNIb35vC2jV_",
        "outputId": "9c9472e6-84e6-4485-bde6-6f63d45654d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+\n",
            "| id|full_name|\n",
            "+---+---------+\n",
            "|  1|    Alice|\n",
            "|  2|      Bob|\n",
            "+---+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.where() & filter()**\n",
        "#### *Both methods are used to filter rows based on conditions.*"
      ],
      "metadata": {
        "id": "b1dxGMsh2nIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df_from_rdd.where(F.col(\"id\")>1)\n",
        "df_filtered.show()\n",
        "\n",
        "#alternatively, use filter()\n",
        "df_filtered = df_from_rdd.filter(F.col(\"id\")>1)\n",
        "df_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfjtHEzG2neI",
        "outputId": "87d1f7e3-1c22-4596-d231-c0f0c3bb9e04"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  2| Bob|\n",
            "+---+----+\n",
            "\n",
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  2| Bob|\n",
            "+---+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12. drop() & dropDuplicates()**\n",
        "#### *Used to drop a column or remove duplicate rows*"
      ],
      "metadata": {
        "id": "VhyNgzcE2ntN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping a column\n",
        "df_dropped = df_from_rdd.drop(\"name\")\n",
        "df_dropped.show()\n",
        "\n",
        "#Removing duplicates\n",
        "df_no_duplicates = df_from_rdd.dropDuplicates()\n",
        "df_no_duplicates.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP_fanTm2n09",
        "outputId": "407799bb-425d-4f8b-a76d-8c79aa1e3c2d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  1|\n",
            "|  2|\n",
            "+---+\n",
            "\n",
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  2|  Bob|\n",
            "|  1|Alice|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **13. orderBy() and sort()**\n",
        "#### *These methods are used for sorting data in DataFrame*"
      ],
      "metadata": {
        "id": "I-oQlqiS2n9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted = df_from_rdd.orderBy(\"id\", ascending=False)\n",
        "df_sorted.show()\n",
        "\n",
        "#Equivalent to orderBy()\n",
        "df_sorted2 = df_from_rdd.sort(\"id\")\n",
        "df_sorted2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU5HZznq2oCu",
        "outputId": "cfa7e2f7-bd84-4e3d-e199-f59a43883ff6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  2|  Bob|\n",
            "|  1|Alice|\n",
            "+---+-----+\n",
            "\n",
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  1|Alice|\n",
            "|  2|  Bob|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. **groupBy()**\n",
        "#### *Used for group-by operations*"
      ],
      "metadata": {
        "id": "tdEEJ-212oJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped= df_from_rdd.groupBy(\"id\").count()\n",
        "df_grouped.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPT4rEli2oPt",
        "outputId": "e4c8e372-f2f7-4604-a8de-817b153f20bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id|count|\n",
            "+---+-----+\n",
            "|  1|    1|\n",
            "|  2|    1|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **15. join()**\n",
        "#### *Used for joining DataFrames.*"
      ],
      "metadata": {
        "id": "9kXmqGvw2oXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2= spark.createDataFrame(\n",
        "    data= [(1,\"Math\"),(2,\"Science\")],\n",
        "    schema=[\"id\",\"name\"]\n",
        ")\n",
        "df_joined = df_from_rdd.join(df2, on=\"id\")\n",
        "df_joined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2u0Y11s2oeh",
        "outputId": "f6c6066b-85c2-4597-decd-92d6feb3a611"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-------+\n",
            "| id| name|   name|\n",
            "+---+-----+-------+\n",
            "|  1|Alice|   Math|\n",
            "|  2|  Bob|Science|\n",
            "+---+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16. **union() & unionAll()**\n",
        "#### *Both methods combine DataFrames, but unionAll is deprecated in favor of union()*"
      ],
      "metadata": {
        "id": "f_aKQudt2ol4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3= spark.createDataFrame(\n",
        "    data= [(3,\"Charlie\")],\n",
        "    schema=[\"id\",\"name\"]\n",
        ")\n",
        "df_union = df_from_rdd.union(df3)\n",
        "df_union.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiYLINaC2osB",
        "outputId": "1f4a396e-a89d-416c-aad3-c0b4d9633eee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+\n",
            "| id|   name|\n",
            "+---+-------+\n",
            "|  1|  Alice|\n",
            "|  2|    Bob|\n",
            "|  3|Charlie|\n",
            "+---+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **17. unionByName()**\n",
        "#### *Union DataFrames by column name*"
      ],
      "metadata": {
        "id": "ZiVwC49q2ozU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_union_by_name = df_from_rdd.unionByName(df2)\n",
        "df_union_by_name.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH2YuGMF2o6x",
        "outputId": "71bb3743-6c79-47f6-93c8-94ca18930240"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+\n",
            "| id|   name|\n",
            "+---+-------+\n",
            "|  1|  Alice|\n",
            "|  2|    Bob|\n",
            "|  1|   Math|\n",
            "|  2|Science|\n",
            "+---+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **18. UDF (User Defined Function)**\n",
        "#### *UDFs are used to extend the functionality of Spark DataFrame with custom logic*"
      ],
      "metadata": {
        "id": "llUbwmc52pDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def add_exclamation(name):\n",
        "  return name + \"!\"\n",
        "\n",
        "add_udf = udf(add_exclamation, StringType())\n",
        "df_udf = df_from_rdd.withColumn(\"excited_name\", add_udf(\"name\"))\n",
        "df_udf.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7pIfDyb2pOF",
        "outputId": "94222c15-642b-45d0-f20c-68b5e70e66fe"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+------------+\n",
            "| id| name|excited_name|\n",
            "+---+-----+------------+\n",
            "|  1|Alice|      Alice!|\n",
            "|  2|  Bob|        Bob!|\n",
            "+---+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **19. transform()**\n",
        "#### *transform() is used to apply transformations to a DataFrame*"
      ],
      "metadata": {
        "id": "UwUdq69P_ZAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_transformed = df_from_rdd.transform(lambda df: df.withColumn(\"id_squared\", df[\"id\"]**2))\n",
        "df_transformed.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFFFjOcB-_VJ",
        "outputId": "a89f9c8c-5ae6-4e80-a7da-0ba846283972"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+\n",
            "| id| name|id_squared|\n",
            "+---+-----+----------+\n",
            "|  1|Alice|       1.0|\n",
            "|  2|  Bob|       4.0|\n",
            "+---+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 20. apply()\n",
        "#### transform() is used to apply transformations to a DataFrame."
      ],
      "metadata": {
        "id": "6yRlntgp_Zy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_applied = df_from_rdd.rdd.map(lambda row: (row.id*2, row.name)).toDF([\"id\",\"name\"])\n",
        "df_applied.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJxnqeci_aQ9",
        "outputId": "e590db74-1c71-4f54-9442-4ab59d417e66"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  2|Alice|\n",
            "|  4|  Bob|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **21. map()**\n",
        "#### *map() is used on an RDD to apply a function on each element*"
      ],
      "metadata": {
        "id": "LCTZGMs-_aZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_mapped = df_from_rdd.rdd.map(lambda x: (x.id*2, x.name))\n",
        "df_mapped = rdd_mapped.toDF([\"id\",\"name\"])\n",
        "df_mapped.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95yCgsEd_agl",
        "outputId": "f07b6f96-3513-4dab-ba19-05f82e5c4082"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  2|Alice|\n",
            "|  4|  Bob|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **22. flatMap()**\n",
        "#### *Used to flaten a collection on items*"
      ],
      "metadata": {
        "id": "lG5-nuc8_aoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_flat = df_from_rdd.rdd.flatMap(lambda x: [(x.id, x.name), (x.id*10, x.name)])\n",
        "print(rdd_flat.collect())\n",
        "df_flat = rdd_flat.toDF([\"id\",\"name\"])\n",
        "df_flat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKaAOGfs_awG",
        "outputId": "75f928bc-9c25-4679-febe-19b4b2f0dfda"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 'Alice'), (10, 'Alice'), (2, 'Bob'), (20, 'Bob')]\n",
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  1|Alice|\n",
            "| 10|Alice|\n",
            "|  2|  Bob|\n",
            "| 20|  Bob|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example list of sentences\n",
        "sentences = [\n",
        "    \"Hello world\",\n",
        "    \"This is Spark\",\n",
        "    \"flatMap example\",\n",
        "    \"Filter me out\"\n",
        "]\n",
        "rdd2= spark.sparkContext.parallelize(sentences)\n",
        "rdd_filtered  = rdd2.flatMap(lambda sentence: [(word,) for word in sentence.split(\" \") if word!=\"me\"])\n",
        "df_required_filtered= rdd_filtered.toDF([\"word\"])\n",
        "df_required_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYvBSBBY_bOU",
        "outputId": "ce7f1a91-c134-4153-c4da-b47e367ba2f9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|   word|\n",
            "+-------+\n",
            "|  Hello|\n",
            "|  world|\n",
            "|   This|\n",
            "|     is|\n",
            "|  Spark|\n",
            "|flatMap|\n",
            "|example|\n",
            "| Filter|\n",
            "|    out|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PrshaQMZ_a3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pwaJoVGa_bGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RfXNmoHb_bXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byYfEDQt_bem",
        "outputId": "1ed4f6b3-a953-4b84-d5c1-b193e8cd0d20"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello world', 'This is Spark', 'flatMap example', 'Filter me out']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_filtered  = rdd2.flatMap(lambda sentence: [(word,) for word in sentence.split(\" \") if word!=\"me\"])"
      ],
      "metadata": {
        "id": "1U6TrSadQYle"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_filtered.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmmzITlOQYzO",
        "outputId": "23390e5b-acd2-4059-fdc0-2dc743a0c83f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hello',),\n",
              " ('world',),\n",
              " ('This',),\n",
              " ('is',),\n",
              " ('Spark',),\n",
              " ('flatMap',),\n",
              " ('example',),\n",
              " ('Filter',),\n",
              " ('out',)]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_required_filtered= rdd_filtered.toDF([\"word\"])\n",
        "df_required_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDMWt8CzQuJ7",
        "outputId": "370fb891-3aaf-4f61-c13a-a2bee4497001"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|   word|\n",
            "+-------+\n",
            "|  Hello|\n",
            "|  world|\n",
            "|   This|\n",
            "|     is|\n",
            "|  Spark|\n",
            "|flatMap|\n",
            "|example|\n",
            "| Filter|\n",
            "|    out|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **23. foreach()**\n",
        "#### *foreach() is used for applying a function to each row in the DataFrame.*"
      ],
      "metadata": {
        "id": "43CMt1oa_bm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_row(row):\n",
        "  print(row)\n",
        "df_from_rdd.foreach(print_row)\n"
      ],
      "metadata": {
        "id": "XTIljqiv_btf"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **24. sample() vs sampleBy()**\n",
        "#### *sample() is used for random.sampling, while sampleBy() allows sampling with satisfaction*"
      ],
      "metadata": {
        "id": "XOVarEOA_b2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sample()\n",
        "df_sample = df_from_rdd.sample(fraction=0.5)\n",
        "df_sample.show()\n",
        "\n",
        "#sampleBy()\n",
        "df_sample_by = df_from_rdd.sampleBy(\"id\", fractions={1:0.5,2:0.5})\n",
        "df_sample_by.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH5Oe_XP_b_L",
        "outputId": "c382a81b-4eec-4c98-9724-9364d439ac6d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  1|Alice|\n",
            "|  2|  Bob|\n",
            "+---+-----+\n",
            "\n",
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  2| Bob|\n",
            "+---+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **25. fillna()**\n",
        "*Used for handling missing values.*"
      ],
      "metadata": {
        "id": "KDtdaVUDmI_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fillna()\n",
        "df_null = spark.createDataFrame(\n",
        "    data=[(1, None), (2, \"sanjeev2\"),(None, None), (None, \"sanjeev4\")],\n",
        "    schema= [\"id\",\"name\"]\n",
        ")\n",
        "df_fillna = df_null.fillna({\"id\":0, \"name\":\"Unknown\"})\n",
        "df_fillna.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYaBAXL0mJJU",
        "outputId": "7436dcea-1097-4518-abab-4cea641fee0c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "| id|    name|\n",
            "+---+--------+\n",
            "|  1| Unknown|\n",
            "|  2|sanjeev2|\n",
            "|  0| Unknown|\n",
            "|  0|sanjeev4|\n",
            "+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **26. pivot() (Row to Column)**\n",
        "#### *Used to pivot data (convert rows to columns).*"
      ],
      "metadata": {
        "id": "ve_ewkKw_cIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivoted = df_from_rdd.groupBy(\"id\").pivot(\"name\").agg({\"id\":\"count\"})\n",
        "df_pivoted.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEnrbOCz_cSY",
        "outputId": "24c4119b-cc0d-4812-d689-020ef71357c4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----+\n",
            "| id|Alice| Bob|\n",
            "+---+-----+----+\n",
            "|  1|    1|NULL|\n",
            "|  2| NULL|   1|\n",
            "+---+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **27. repartitionByRange() and repartition()**\n",
        "#### *Re-Partitioning the data by one or more columns for distributed processing.*"
      ],
      "metadata": {
        "id": "9W143Bpg_cae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_partitioning = spark.createDataFrame(\n",
        "    data=[(1, \"A\"), (2, \"B\"),(3, \"C\"), (4, \"D\"), (5, \"E\"), (6, \"F\")],\n",
        "    schema= [\"id\",\"name\"]\n",
        ")\n",
        "\n",
        "#repartitionByRange\n",
        "df_repartitionByRange = df_for_partitioning.repartitionByRange(2,\"id\")\n",
        "print(df_repartitionByRange.rdd.getNumPartitions())\n",
        "df_repartitionByRange.withColumn(\"partition_id\", F.spark_partition_id()).show()\n",
        "\n",
        "#repartition\n",
        "df_repartition = df_for_partitioning.repartition(2,\"id\")\n",
        "print(df_repartition.rdd.getNumPartitions())\n",
        "df_repartition.withColumn(\"partition_id\", F.spark_partition_id()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tma0dbREjU0c",
        "outputId": "ca98f023-274c-4304-9368-6cf98c7eadc3"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "+---+----+------------+\n",
            "| id|name|partition_id|\n",
            "+---+----+------------+\n",
            "|  1|   A|           0|\n",
            "|  2|   B|           0|\n",
            "|  3|   C|           0|\n",
            "|  4|   D|           1|\n",
            "|  5|   E|           1|\n",
            "|  6|   F|           1|\n",
            "+---+----+------------+\n",
            "\n",
            "2\n",
            "+---+----+------------+\n",
            "| id|name|partition_id|\n",
            "+---+----+------------+\n",
            "|  2|   B|           0|\n",
            "|  4|   D|           0|\n",
            "|  5|   E|           0|\n",
            "|  1|   A|           1|\n",
            "|  3|   C|           1|\n",
            "|  6|   F|           1|\n",
            "+---+----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 28. **MapType (Map / Dict)**\n",
        "#### *MapType is used for columns that represent key-value pairs*"
      ],
      "metadata": {
        "id": "DH3EokuJtcc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import MapType, StringType\n",
        "\n",
        "data = [(1, {\"name\": \"Alice\",\"age\":\"25\"}), (2,{\"name\":\"Bob\",\"age\":\"30\"})]\n",
        "schema = StructType([\n",
        "    StructField(\"id\",IntegerType(),True),\n",
        "    StructField(\"info\", MapType(StringType(), StringType()), True)\n",
        "])\n",
        "df_map = spark.createDataFrame(data, schema)\n",
        "df_map.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQDPqYqfsBML",
        "outputId": "d87f0939-06aa-46f8-9dc0-55525de3a446"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+\n",
            "| id|                info|\n",
            "+---+--------------------+\n",
            "|  1|{name -> Alice, a...|\n",
            "|  2|{name -> Bob, age...|\n",
            "+---+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2T_QAjMtolv5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}